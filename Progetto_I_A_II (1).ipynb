{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Librerie"
      ],
      "metadata": {
        "id": "dBz0euEw9dPz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHIkVC8Gs8lp"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ucimlrepo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Caricamento del Dataset"
      ],
      "metadata": {
        "id": "isWYPwYW9o6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
        "\n",
        "X = infrared_thermography_temperature.data.features\n",
        "y = infrared_thermography_temperature.data.targets\n",
        "\n",
        "\n",
        "print(infrared_thermography_temperature.metadata)\n",
        "print(infrared_thermography_temperature.variables)\n"
      ],
      "metadata": {
        "id": "v5vbLxzZuUwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prima visione dell'input"
      ],
      "metadata": {
        "id": "B4LM7DEaBgpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()\n",
        "X.describe()"
      ],
      "metadata": {
        "id": "u-uLccveBOoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prima visione dell'output"
      ],
      "metadata": {
        "id": "NXmOkFpVBoXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()\n",
        "y.describe()"
      ],
      "metadata": {
        "id": "0-3Jo_X0BT0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train-test splitting"
      ],
      "metadata": {
        "id": "V3Ivk1__K6Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Dimensione di X_train_raw: {X_train_raw.shape}\")\n",
        "print(f\"Dimensione di y_train: {y_train.shape}\")\n",
        "print(f\"Dimensione di X_test_raw: {X_test_raw.shape}\")\n",
        "print(f\"Dimensione di y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "dptvaqASK5i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.describe()"
      ],
      "metadata": {
        "id": "wAlBOWv8XWrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.describe()"
      ],
      "metadata": {
        "id": "eM8r6KmCXoEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "3pyuAiaL_xuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_features(df_X, training_cols=None):\n",
        "    df_X_copy = df_X.copy() # Lavora su una copia del DataFrame\n",
        "\n",
        "    # Sostituisce i valori inf con NaN per primi\n",
        "    df_X_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Riempie i valori NaN per le colonne numeriche con la loro media (calcolata all'interno di ogni split per ora)\n",
        "    for col in df_X_copy.select_dtypes(include=np.number).columns:\n",
        "        if df_X_copy[col].isnull().any():\n",
        "            df_X_copy[col] = df_X_copy[col].fillna(df_X_copy[col].mean())\n",
        "\n",
        "    # One-Hot Encoding per le variabili categoriche\n",
        "    categorical_cols = df_X_copy.select_dtypes(include='object').columns\n",
        "    if not categorical_cols.empty:\n",
        "        df_X_encoded = pd.get_dummies(df_X_copy, columns=categorical_cols, drop_first=True)\n",
        "    else:\n",
        "        df_X_encoded = df_X_copy\n",
        "\n",
        "    return df_X_encoded\n",
        "\n",
        "# Applica il preprocessing alle feature di training e test\n",
        "X_train_encoded_df = preprocess_features(X_train_raw)\n",
        "X_test_encoded_df = preprocess_features(X_test_raw)\n",
        "\n",
        "# Inizializza StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Applica lo scaler a X_train_encoded_df e trasforma tutti i set\n",
        "# Converte in array numpy dopo la scalatura\n",
        "X_train = scaler.fit_transform(X_train_encoded_df)\n",
        "X_test = scaler.transform(X_test_encoded_df)\n",
        "\n",
        "# Funzione per il preprocessing dei dati y (target) - gestisce solo NaN/inf, nessuna normalizzazione\n",
        "def preprocess_targets(df_y):\n",
        "    df_y_copy = df_y.copy() # Lavora su una copia del DataFrame\n",
        "\n",
        "    df_y_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    for col in df_y_copy.select_dtypes(include=np.number).columns:\n",
        "        if df_y_copy[col].isnull().any():\n",
        "            df_y_copy[col] = df_y_copy[col].fillna(df_y_copy[col].mean())\n",
        "\n",
        "    return df_y_copy.values # Converte in array numpy\n",
        "\n",
        "# Applica il preprocessing ai target di training e test\n",
        "y_train = preprocess_targets(y_train)\n",
        "y_test = preprocess_targets(y_test)\n",
        "\n",
        "print(f\"Dimensione di X_train (scalato): {X_train.shape}\")\n",
        "print(f\"Dimensione di y_train (preprocessato): {y_train.shape}\")\n",
        "print(f\"Dimensione di X_test (scalato): {X_test.shape}\")\n",
        "print(f\"Dimensione di y_test (preprocessato): {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NIiZvlZ_uVWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "nsllpqd1J021"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrice di correlazione e distribuzione target"
      ],
      "metadata": {
        "id": "fJy6FMxF0JrZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b3aee59"
      },
      "source": [
        "\n",
        "# Utilizziamo X_train_encoded_df che è il DataFrame con le colonne one-hot encoded\n",
        "feature_names_for_eda = X_train_encoded_df.columns\n",
        "\n",
        "# Recupera i nomi delle colonne delle variabili target originali\n",
        "target_names = infrared_thermography_temperature.data.targets.columns\n",
        "\n",
        "# Crea un DataFrame combinato per il training set per l'analisi di correlazione\n",
        "# Usiamo X_train_encoded_df (non scalato) per un'EDA più significativa delle correlazioni\n",
        "df_train_eda = pd.DataFrame(X_train_encoded_df, columns=feature_names_for_eda)\n",
        "for i, name in enumerate(target_names):\n",
        "    df_train_eda[name] = y_train[:, i]\n",
        "\n",
        "print(\"### Matrice di Correlazione ###\")\n",
        "plt.figure(figsize=(20, 18))\n",
        "sns.heatmap(df_train_eda.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matrice di Correlazione del Training Set (Pre-scalatura)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n### Distribuzione delle Label (Variabili Target) ###\")\n",
        "plt.figure(figsize=(14, 6))\n",
        "for i, name in enumerate(target_names):\n",
        "    plt.subplot(1, len(target_names), i + 1)\n",
        "    sns.histplot(y_train[:, i], kde=True)\n",
        "    plt.title(f'Distribuzione di {name}')\n",
        "    plt.xlabel(name)\n",
        "    plt.ylabel('Frequenza')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pairplot delle feature continue"
      ],
      "metadata": {
        "id": "ERON8Q230RnL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28199c1a"
      },
      "source": [
        "\n",
        "#Identifica le feature numeriche originali dal dataset non processato\n",
        "native_numerical_feature_names = infrared_thermography_temperature.data.features.select_dtypes(include=np.number).columns\n",
        "\n",
        "#Ottieni gli indici di queste feature all'interno di X_train_encoded_df\n",
        "#Usiamo X_train_encoded_df per l'EDA perché è il DataFrame con feature one-hot encoded ma non scalate\n",
        "processed_feature_names_for_eda = X_train_encoded_df.columns\n",
        "indices_native_numerical = [processed_feature_names_for_eda.get_loc(col) for col in native_numerical_feature_names if col in processed_feature_names_for_eda]\n",
        "\n",
        "#Crea un DataFrame per il pairplot usando solo queste feature da X_train_encoded_df\n",
        "df_pairplot_numerical = pd.DataFrame(X_train_encoded_df.iloc[:, indices_native_numerical], columns=native_numerical_feature_names)\n",
        "\n",
        "#Aggiungi le variabili target al DataFrame\n",
        "target_names = infrared_thermography_temperature.data.targets.columns\n",
        "for i, name in enumerate(target_names):\n",
        "    df_pairplot_numerical[name] = y_train[:, i]\n",
        "\n",
        "print(\"### Pairplot delle Feature Nativamente Numeriche e Target (Training Set) ###\")\n",
        "sns.pairplot(df_pairplot_numerical, diag_kind='kde')\n",
        "plt.suptitle('Pairplot delle Feature Nativamente Numeriche e Target (Training Set)', y=1.02) # y modifica la posizione del titolo\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "zCt0nTGd0c29"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a204cefc"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "model_oralF = ElasticNet(l1_ratio=0.25, alpha=0.01, random_state=42)\n",
        "model_oralM = ElasticNet(l1_ratio=0.25, alpha=0.01, random_state=42)\n",
        "\n",
        "model_oralF.fit(X_train, y_train[:, 0])\n",
        "model_oralM.fit(X_train, y_train[:, 1])\n",
        "\n",
        "y_train_pred_oralF = model_oralF.predict(X_train)\n",
        "\n",
        "#Calcola il Mean Absolute Error (MAE) e R^2 per aveOralF sul training set\n",
        "mae_train_oralF = mean_absolute_error(y_train[:, 0], y_train_pred_oralF)\n",
        "r2_train_oralF = r2_score(y_train[:, 0], y_train_pred_oralF)\n",
        "print(f\"MAE sul Training Set per aveOralF: {mae_train_oralF:.4f}\")\n",
        "print(f\"R^2 sul Training Set per aveOralF: {r2_train_oralF:.4f}\")\n",
        "\n",
        "#Ripetere i passaggi per AveOralM\n",
        "y_train_pred_oralM = model_oralM.predict(X_train)\n",
        "\n",
        "mae_train_oralM = mean_absolute_error(y_train[:, 1], y_train_pred_oralM)\n",
        "r2_train_oralM = r2_score(y_train[:, 1], y_train_pred_oralM)\n",
        "print(f\"MAE sul Training Set per aveOralM: {mae_train_oralM:.4f}\")\n",
        "print(f\"R^2 sul Training Set per aveOralM: {r2_train_oralM:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modello lineare senza regolarizzazione"
      ],
      "metadata": {
        "id": "vWkTz1_TFc3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_model_oralF = LinearRegression()\n",
        "linear_model_oralM = LinearRegression()\n",
        "\n",
        "linear_model_oralF.fit(X_train, y_train[:, 0])\n",
        "linear_model_oralM.fit(X_train, y_train[:, 1])\n",
        "\n",
        "y_train_pred_oralF_linear = linear_model_oralF.predict(X_train)\n",
        "\n",
        "mae_train_oralF_linear = mean_absolute_error(y_train[:, 0], y_train_pred_oralF_linear)\n",
        "r2_train_oralF_linear = r2_score(y_train[:, 0], y_train_pred_oralF_linear)\n",
        "print(f\"Risultati del Modello Lineare (senza regolarizzazione) sul Training Set per aveOralF\")\n",
        "print(f\"MAE per aveOralF: {mae_train_oralF_linear:.4f}\")\n",
        "print(f\"R^2 per aveOralF: {r2_train_oralF_linear:.4f}\")\n",
        "\n",
        "\n",
        "y_train_pred_oralM_linear = linear_model_oralM.predict(X_train)\n",
        "\n",
        "mae_train_oralM_linear = mean_absolute_error(y_train[:, 1], y_train_pred_oralM_linear)\n",
        "r2_train_oralM_linear = r2_score(y_train[:, 1], y_train_pred_oralM_linear)\n",
        "print(f\"\\nRisultati del Modello Lineare (senza regolarizzazione) sul Training Set per aveOralM\")\n",
        "print(f\"MAE per aveOralM: {mae_train_oralM_linear:.4f}\")\n",
        "print(f\"R^2 per aveOralM: {r2_train_oralM_linear:.4f}\")\n"
      ],
      "metadata": {
        "id": "_owFa8gXFo7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validazione"
      ],
      "metadata": {
        "id": "8OtTEQfXfzsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Definire la griglia di parametri per GridSearchCV\n",
        "param_grid = {\n",
        "    'alpha': np.logspace(-4, 0, 5), # es., 0.0001, 0.001, 0.01, ecc..\n",
        "    'l1_ratio': np.arange(0.0, 1.1, 0.25) # es., 0.0, 0.25, 0.5, ecc..\n",
        "}\n",
        "\n",
        "#Definire le metriche\n",
        "metriche = {\n",
        "    'neg_mae': 'neg_mean_absolute_error', # massimizzazione della metrica\n",
        "    'r2': 'r2'\n",
        "}\n",
        "\n",
        "#Hyperparameter Tuning per aveOralF\n",
        "print(\"Hyperparameter Tuning per aveOralF\")\n",
        "elastic_net_oralF = ElasticNet(random_state=42)\n",
        "grid_search_oralF = GridSearchCV(\n",
        "    elastic_net_oralF,\n",
        "    param_grid,\n",
        "    scoring=metriche, # Usare più metriche\n",
        "    refit='neg_mae', # Riaddestra utilizzando MAE\n",
        "    cv=5, # 5-fold cross-validation\n",
        "    n_jobs=-1 # Usare tutti i core disponibili\n",
        ")\n",
        "grid_search_oralF.fit(X_train, y_train[:, 0])\n",
        "\n",
        "print(f\"Migliori iperparametri per aveOralF: {grid_search_oralF.best_params_}\")\n",
        "print(f\"Miglior MAE per aveOralF (da CV): {-grid_search_oralF.best_score_:.4f}\") # Convertire negative MAE\n",
        "# Calcolare il punteggio R^2\n",
        "best_oralF_idx = grid_search_oralF.cv_results_['rank_test_neg_mae'].argmin()\n",
        "r2_oralF_best_params = grid_search_oralF.cv_results_['mean_test_r2'][best_oralF_idx]\n",
        "print(f\"R^2 per aveOralF (da CV con migliori iperparametri): {r2_oralF_best_params:.4f}\")\n",
        "\n",
        "#Hyperparameter Tuning per aveOralM\n",
        "print(\"\\nHyperparameter Tuning per aveOralM\")\n",
        "elastic_net_oralM = ElasticNet(random_state=42)\n",
        "grid_search_oralM = GridSearchCV(\n",
        "    elastic_net_oralM,\n",
        "    param_grid,\n",
        "    scoring=metriche,\n",
        "    refit='neg_mae',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search_oralM.fit(X_train, y_train[:, 1])\n",
        "\n",
        "print(f\"Migliori iperparametri per aveOralM: {grid_search_oralM.best_params_}\")\n",
        "print(f\"Miglior MAE per aveOralM (da CV): {-grid_search_oralM.best_score_:.4f}\") # Convertire negative MAE\n",
        "best_oralM_idx = grid_search_oralM.cv_results_['rank_test_neg_mae'].argmin()\n",
        "r2_oralM_best_params = grid_search_oralM.cv_results_['mean_test_r2'][best_oralM_idx]\n",
        "print(f\"R^2 per aveOralM (da CV con migliori iperparametri): {r2_oralM_best_params:.4f}\")\n",
        "\n",
        "#Salviamo i migliori modelli trovati da GridSearchCV\n",
        "best_model_oralF = grid_search_oralF.best_estimator_\n",
        "best_model_oralM = grid_search_oralM.best_estimator_"
      ],
      "metadata": {
        "id": "t5HIM5mvf3b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "ZjInG7Twjm5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predizioni di modello con regolarizzazione"
      ],
      "metadata": {
        "id": "n0uQB_N8IC1J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81399a72"
      },
      "source": [
        "y_pred_oralF = best_model_oralF.predict(X_test)\n",
        "y_pred_oralM = best_model_oralM.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predizioni di modello lineare senza regolarizzazione"
      ],
      "metadata": {
        "id": "ZTWxa8I-IF-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizioni del modello lineare senza regolarizzazione sul test set\n",
        "y_pred_oralF_linear = linear_model_oralF.predict(X_test)\n",
        "y_pred_oralM_linear = linear_model_oralM.predict(X_test)\n"
      ],
      "metadata": {
        "id": "kNTXkSOpIMbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing e grafici"
      ],
      "metadata": {
        "id": "KAxr68WBKWW_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0badfeca"
      },
      "source": [
        "\n",
        "#Valutazione per ElasticNet (aveOralF)\n",
        "print(\"Valutazione ElasticNet per aveOralF\")\n",
        "mae_oralF_elastic = mean_absolute_error(y_test[:, 0], y_pred_oralF)\n",
        "r2_oralF_elastic = r2_score(y_test[:, 0], y_pred_oralF)\n",
        "\n",
        "print(f\"MAE (aveOralF ElasticNet): {mae_oralF_elastic:.4f}\")\n",
        "print(f\"R2 Score (aveOralF ElasticNet): {r2_oralF_elastic:.4f}\")\n",
        "\n",
        "# Analisi grafica dei Residui per aveOralF (ElasticNet)\n",
        "residuals_oralF_elastic = y_test[:, 0] - y_pred_oralF\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.scatterplot(x=y_test[:, 0], y=residuals_oralF_elastic)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Analisi dei Residui per aveOralF (ElasticNet)\")\n",
        "plt.xlabel(\"Valori Target Reali (aveOralF)\")\n",
        "plt.ylabel(\"Residui (aveOralF)\")\n",
        "plt.show()\n",
        "\n",
        "#Valutazione per ElasticNet (aveOralM)\n",
        "print(\"\\nValutazione ElasticNet per aveOralM\")\n",
        "mae_oralM_elastic = mean_absolute_error(y_test[:, 1], y_pred_oralM)\n",
        "r2_oralM_elastic = r2_score(y_test[:, 1], y_pred_oralM)\n",
        "\n",
        "print(f\"MAE (aveOralM ElasticNet): {mae_oralM_elastic:.4f}\")\n",
        "print(f\"R2 Score (aveOralM ElasticNet): {r2_oralM_elastic:.4f}\")\n",
        "\n",
        "# Analisi Grafica dei Residui per aveOralM (ElasticNet)\n",
        "residuals_oralM_elastic = y_test[:, 1] - y_pred_oralM\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.scatterplot(x=y_test[:, 1], y=residuals_oralM_elastic)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title(\"Analisi dei Residui per aveOralM (ElasticNet)\")\n",
        "plt.xlabel(\"Valori Target(aveOralM)\")\n",
        "plt.ylabel(\"Residui (aveOralM)\")\n",
        "plt.show()\n",
        "\n",
        "#Valutazione per Modello Lineare (aveOralF)\n",
        "print(\"\\nValutazione Modello Lineare (senza reg.) per aveOralF\")\n",
        "mae_oralF_linear = mean_absolute_error(y_test[:, 0], y_pred_oralF_linear)\n",
        "r2_oralF_linear = r2_score(y_test[:, 0], y_pred_oralF_linear)\n",
        "\n",
        "print(f\"MAE (aveOralF Lineare): {mae_oralF_linear:.4f}\")\n",
        "print(f\"R2 Score (aveOralF Lineare): {r2_oralF_linear:.4f}\")\n",
        "\n",
        "#Valutazione per Modello Lineare (aveOralM)\n",
        "print(\"\\nValutazione Modello Lineare (senza reg.) per aveOralM\")\n",
        "mae_oralM_linear = mean_absolute_error(y_test[:, 1], y_pred_oralM_linear)\n",
        "r2_oralM_linear = r2_score(y_test[:, 1], y_pred_oralM_linear)\n",
        "\n",
        "print(f\"MAE (aveOralM Lineare): {mae_oralM_linear:.4f}\")\n",
        "print(f\"R2 Score (aveOralM Lineare): {r2_oralM_linear:.4f}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
